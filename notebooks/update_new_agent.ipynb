{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc823b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/multi_agents/graph/state.py\n",
    "\n",
    "from typing import TypedDict, List, Dict, Any, Optional, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # User request\n",
    "    original_query: str\n",
    "\n",
    "    # Planning & history\n",
    "    plan: List[Dict[str, Any]]\n",
    "    past_steps: List[Dict[str, Any]]\n",
    "\n",
    "    # Intelligence Stores\n",
    "    aggregated_results: Dict[str, Any]\n",
    "    airbnb_host_data: Optional[Dict[str, Any]]\n",
    "\n",
    "    # Final report (filled by ReportSynthesizer)\n",
    "    final_report: str\n",
    "\n",
    "    # Conversation buffer for the graph\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "\n",
    "    # Transient values passed between nodes\n",
    "    last_step_result: Optional[Dict[str, Any]]\n",
    "    last_step_message: Optional[BaseMessage]\n",
    "\n",
    "    # Human-in-the-loop (HITL) - Kept for future extension\n",
    "    awaiting_user_confirmation: bool\n",
    "    candidate_options: List[Dict[str, Any]]\n",
    "    selected_candidate: Optional[Dict[str, Any]]\n",
    "\n",
    "    # NEW: Step tracking and control fields\n",
    "    current_step: int\n",
    "    max_steps: int\n",
    "    executed_tasks: List[str]  # Track what tasks have been attempted\n",
    "    failed_approaches: List[str]  # Track failed strategies to avoid repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### `workers_prompts.py`\n",
    "\n",
    "\"\"\"\n",
    "This file contains the master prompts and persona descriptions for the specialist worker agents.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "BASE_WORKER_PROMPT = \"\"\"\n",
    "# IDENTITY & MISSION\n",
    "You are a specialist OSINT Field Agent named {name}. You are a vital component of a larger multi-agent intelligence team. Your mission is to execute your assigned task with precision and generate actionable intelligence for your fellow agents.\n",
    "{persona}\n",
    "\n",
    "INVESTIGATION PROGRESS: Step {current_step} of {max_steps} as a max step.\n",
    "\n",
    "# TEAM CONTEXT & OVERALL OBJECTIVE\n",
    "The team's primary mission is to answer this query: \"{original_query}\" with the following information snapshot about the airbnb host as ground truth. Do not contradict it and do not infer fields that aren't present.\n",
    "<info>\n",
    "{airbnb_host_data}\n",
    "</info>\n",
    "\n",
    "# INVESTIGATION STATE AWARENESS\n",
    "<Previously_Executed_Tasks>\n",
    "{executed_tasks}\n",
    "</Previously_Executed_Tasks>\n",
    "\n",
    "<Failed_Approaches_To_Avoid>\n",
    "{failed_approaches}\n",
    "</Failed_Approaches_To_Avoid>\n",
    "\n",
    "<Current_Intelligence_Gathered>\n",
    "{aggregated_results}\n",
    "</Current_Intelligence_Gathered>\n",
    "\n",
    "# YOUR CURRENT ASSIGNMENT\n",
    "The Mission Commander (Supervisor) has deployed you with the following specific task: \"{task}\"\n",
    "You must use your specialized tools to fulfill this task. Your success will be measured by both the quality of your direct answer and the new leads you generate for the team.\n",
    "# STRATEGIC DIRECTIVES FOR SUCCESS\n",
    "1. **AVOID REPETITION**: Do NOT repeat any previously executed tasks from the list above\n",
    "2. **AVOID SEARCH ON AIRBNB**: Do not search on airbnb becouse the <info></info> is scraped from airbnb.\n",
    "2. **LEARN FROM FAILURES**: Avoid approaches that have already failed\n",
    "3. **BUILD ON SUCCESS**: Leverage existing intelligence to find NEW leads and identities\n",
    "4. **HIGH-VALUE TARGETS**: Prioritize finding:\n",
    "   - Real names and aliases\n",
    "   - Social media profiles with verification potential\n",
    "   - Business/professional connections\n",
    "   - Location-specific information\n",
    "   - Contact details (email, phone)\n",
    "\n",
    "# FRAMEWORK & OUTPUT\n",
    "You must operate using the ReAct (Reason-Act-Observe) framework.\n",
    "\n",
    "**TOOLS:**\n",
    "------\n",
    "{tools}\n",
    "\n",
    "**OUTPUT FORMAT:**\n",
    "------\n",
    "To use a tool, you **MUST** use this exact format:\n",
    "```\n",
    "Thought: [Your reasoning about the next action based on the task and available data.]\n",
    "Action: [the name of the tool to use from this list: {tool_names}]\n",
    "Action Input: [the input to the tool, which can be a string or a JSON object]\n",
    "```\n",
    "\n",
    "After you write `Action Input:`, **stop your message immediately** and wait for the tool result (Observation).\n",
    "\n",
    "When you have fulfilled your task, provide your final answer in the ReAct `Final Answer:` format. Your answer should be a comprehensive summary of your findings and any new leads discovered.\n",
    "\n",
    "RULES:\n",
    "- You may ONLY call tools from this exact list: {tool_names}.\n",
    "- All facts in your Final Answer must come directly from tool outputs.\n",
    "- If a tool returns an error, try an alternative tool or report the failure in your Final Answer.\n",
    "\n",
    "Final Answer:\n",
    "[Your comprehensive summary and list of new leads.]\n",
    "\"\"\"\n",
    "\n",
    "# --- Persona Descriptions for Each Specialist Worker ---\n",
    "\n",
    "WEB_SEARCH_INVESTIGATOR_PERSONA = \"\"\"\n",
    "Your specialization is **Digital Reconnaissance**. You are an expert in using search engines and web scraping to uncover digital footprints. Your mission is to find social media profiles, public records, news articles, and any other online information related to the target based on names, locations, and other keywords provided by the Supervisor.\n",
    "\"\"\"\n",
    "\n",
    "IMAGE_SEARCH_INVESTIGATOR_PERSONA = \"\"\"\n",
    "Your specialization is **Visual Intelligence (VISINT)**. You are an expert in reverse image searching and facial recognition. Your mission is to take a profile picture and find every other instance of it online, identifying associated profiles on social media, forums, and other websites to link identities across platforms.\n",
    "\"\"\"\n",
    "\n",
    "REPORT_SYNTHESIZER_PROMPT = \"\"\"You are the team's dedicated Intelligence Analyst and Report Synthesizer. Your mission is to transform the final, aggregated intelligence findings into a comprehensive, well-structured, and human-readable final report for the end-user.\n",
    "\n",
    "Original Query: {original_query}\n",
    "\n",
    "\n",
    "Database Ground Truth:\n",
    "{airbnb_host_data}\n",
    "\n",
    "\n",
    "Aggregated Intelligence Findings:\n",
    "{aggregated_results}\n",
    "\n",
    "Create a clean, professional Markdown report. Start with a high-level summary of the investigation's conclusions, followed by detailed sections for each key finding (e.g., Social Media Presence, Contact Information, Location History, etc.). Be thorough and precise.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, Optional, cast\n",
    "from langchain.agents import AgentExecutor, Tool\n",
    "from langchain.agents import create_react_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from multi_agents.tools import search_tools\n",
    "from multi_agents.constants.constants import Constants\n",
    "import logging\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from pydantic import SecretStr\n",
    "import json\n",
    "\n",
    "# from multi_agents.Prompts.workers_prompts import (\n",
    "#     BASE_WORKER_PROMPT,\n",
    "#     WEB_SEARCH_INVESTIGATOR_PERSONA,\n",
    "#     IMAGE_SEARCH_INVESTIGATOR_PERSONA,\n",
    "#     REPORT_SYNTHESIZER_PROMPT,\n",
    "# )\n",
    "\n",
    "\n",
    "class BaseWorker:\n",
    "    def __init__(self, tools: list, name: str, system_prompt_extension: str):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=Constants.WORKER_MODEL,\n",
    "            temperature=0.0,\n",
    "            base_url=Constants.OPENROUTER_BASE_URL,\n",
    "            api_key=SecretStr(Constants.OPENROUTER_API_KEY or \"\")\n",
    "        )\n",
    "        self.tools = tools\n",
    "        self.name = name\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", BASE_WORKER_PROMPT),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"ai\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "\n",
    "        prompt = prompt.partial(\n",
    "            tools=\"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools]),\n",
    "            tool_names=\", \".join([tool.name for tool in tools]),\n",
    "            name=self.name,\n",
    "            persona=system_prompt_extension\n",
    "        )\n",
    "\n",
    "        self.agent = create_react_agent(self.llm, tools, prompt)\n",
    "        self.agent_executor = AgentExecutor(\n",
    "            agent=self.agent,\n",
    "            tools=tools,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True,\n",
    "            max_iterations=8,\n",
    "        )\n",
    "\n",
    "    def run(self, state: Dict[str, Any], config: Optional[RunnableConfig] = None) -> Dict[str, Any]:\n",
    "        try:\n",
    "            # The input for the worker is now a simple dictionary, often just `{\"task\": \"...\"}`\n",
    "            task_input = state[\"plan\"][0][\"inputs\"]\n",
    "            task_string = task_input.get(\"task\", json.dumps(task_input))\n",
    "\n",
    "\n",
    "            agg_results_str = json.dumps(state.get(\"aggregated_results\", {}), indent=2)\n",
    "\n",
    "            db_str = json.dumps(state.get(\"airbnb_host_data\", {}), indent=2)\n",
    "\n",
    "            result = self.agent_executor.invoke({\n",
    "                \"input\": task_string,\n",
    "                \"task\": task_string,\n",
    "                \"original_query\": state[\"original_query\"],\n",
    "                \"aggregated_results\": agg_results_str,\n",
    "                \"airbnb_host_data\": db_str,\n",
    "                \"current_step\": state.get(\"current_step\", 1),\n",
    "                \"max_steps\": state.get(\"max_steps\", 6),\n",
    "                \"executed_tasks\": json.dumps(state.get(\"executed_tasks\", []), ensure_ascii=False),\n",
    "                \"failed_approaches\": json.dumps(state.get(\"failed_approaches\", []), ensure_ascii=False),\n",
    "            }, config)\n",
    "\n",
    "            final_output = result.get(\"output\", f\"No specific output from {self.name}.\")\n",
    "\n",
    "            return {\n",
    "                \"last_step_result\": {\n",
    "                    \"worker\": self.name,\n",
    "                    \"results\": {self.name: final_output},\n",
    "                    \"success\": True\n",
    "                },\n",
    "                \"last_step_message\": AIMessage(content=f\"{self.name} completed its task. Summary: {final_output}\")\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"{self.name} failed: {str(e)}\", exc_info=True)\n",
    "            return {\n",
    "                \"last_step_result\": {\n",
    "                    \"worker\": self.name,\n",
    "                    \"results\": {},\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e)\n",
    "                },\n",
    "                \"last_step_message\": AIMessage(content=f\"{self.name} failed with error: {str(e)}\")\n",
    "            }\n",
    "\n",
    "class WebSearchInvestigator(BaseWorker):\n",
    "    def __init__(self):\n",
    "        tools = [\n",
    "            search_tools.tavily_search,\n",
    "            search_tools.google_search,\n",
    "            search_tools.web_scraper,\n",
    "            search_tools.duckduckgo_search,\n",
    "   \n",
    "            search_tools.yandex_search,\n",
    "            search_tools.yahoo_search,\n",
    "            search_tools.baidu_search,\n",
    "           \n",
    "            search_tools.yelp_search,\n",
    "     \n",
    "        ]\n",
    "        super().__init__(tools, \"WebSearchInvestigator\", WEB_SEARCH_INVESTIGATOR_PERSONA)\n",
    "\n",
    "class ImageSearchInvestigator(BaseWorker):\n",
    "    def __init__(self):\n",
    "        tools = [\n",
    "            search_tools.google_lens_search,\n",
    "            search_tools.bing_images_search,\n",
    "            search_tools.google_image_search\n",
    "        ]\n",
    "        super().__init__(tools, \"ImageSearchInvestigator\", IMAGE_SEARCH_INVESTIGATOR_PERSONA)\n",
    "\n",
    "\n",
    "class ReportSynthesizer:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=Constants.SYNTHESIZER_MODEL,\n",
    "            temperature=0.0,\n",
    "            base_url=Constants.OPENROUTER_BASE_URL,\n",
    "            api_key=SecretStr(Constants.OPENROUTER_API_KEY or \"\")\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def run(self, state: Dict[str, Any], config: Optional[RunnableConfig] = None) -> Dict[str, Any]:\n",
    "        prompt = ChatPromptTemplate.from_template(REPORT_SYNTHESIZER_PROMPT)\n",
    "        chain = prompt | self.llm\n",
    "        try:\n",
    "            # Ensure aggregated_results is a string for the prompt\n",
    "            aggregated_results_str = json.dumps(state.get(\"aggregated_results\", {}), indent=2)\n",
    "\n",
    "            db_str = json.dumps(state.get(\"airbnb_host_data\", {}), indent=2)\n",
    "            report = chain.invoke({\n",
    "                \"original_query\": state[\"original_query\"],\n",
    "                \"aggregated_results\": aggregated_results_str,\n",
    "                \"airbnb_host_data\": db_str,\n",
    "            }, config).content\n",
    "\n",
    "            self.logger.info(\"Report successfully generated\")\n",
    "            return {\n",
    "                \"final_report\": report,\n",
    "                \"last_step_message\": AIMessage(content=\"Final report generated.\")\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to generate report: {str(e)}\")\n",
    "            return {\n",
    "                \"final_report\": f\"Error generating report: {str(e)}\",\n",
    "                \"last_step_message\": AIMessage(content=f\"Failed to generate report: {str(e)}\")\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1cc41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Worker System Implementation\n",
    "\n",
    "import asyncio\n",
    "from typing import Dict, Any, Optional, List\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "import logging\n",
    "import json\n",
    "\n",
    "class Aggregator:\n",
    "    \"\"\"\n",
    "    The responsibility of this class is to receive multiple outputs from multiple workers \n",
    "    and return the aggregated results.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def aggregate_results(self, worker_name: str, task_results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Takes a list of task results and aggregates them into the expected format.\n",
    "        \n",
    "        Args:\n",
    "            worker_name: Name of the worker type (e.g., \"WebSearchInvestigator\")\n",
    "            task_results: List of results from individual tasks\n",
    "            \n",
    "        Returns:\n",
    "            Aggregated result in the expected format\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Combine all results from different tasks\n",
    "            combined_results = {}\n",
    "            all_summaries = []\n",
    "            \n",
    "            for task_result in task_results:\n",
    "                task_name = task_result.get(\"task\", \"unknown_task\")\n",
    "                result_content = task_result.get(\"results\", \"\")\n",
    "                \n",
    "                # Add individual task results\n",
    "                combined_results[f\"{worker_name}_{task_name}\"] = result_content\n",
    "                all_summaries.append(f\"Task: {task_name} - Result: {result_content[:200]}...\")\n",
    "            \n",
    "            # Create overall summary\n",
    "            overall_summary = f\"{worker_name} completed {len(task_results)} tasks. \" + \\\n",
    "                            \" | \".join(all_summaries)\n",
    "            \n",
    "            return {\n",
    "                \"last_step_result\": {\n",
    "                    \"worker\": worker_name,\n",
    "                    \"results\": combined_results,\n",
    "                    \"success\": True,\n",
    "                    \"task_count\": len(task_results),\n",
    "                    \"individual_results\": task_results\n",
    "                },\n",
    "                \"last_step_message\": AIMessage(\n",
    "                    content=f\"{worker_name} completed {len(task_results)} tasks. Summary: {overall_summary}\"\n",
    "                )\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Aggregation failed for {worker_name}: {str(e)}\", exc_info=True)\n",
    "            return {\n",
    "                \"last_step_result\": {\n",
    "                    \"worker\": worker_name,\n",
    "                    \"results\": {},\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e)\n",
    "                },\n",
    "                \"last_step_message\": AIMessage(\n",
    "                    content=f\"{worker_name} aggregation failed with error: {str(e)}\"\n",
    "                )\n",
    "            }\n",
    "\n",
    "\n",
    "class MultiWorker:\n",
    "    \"\"\"\n",
    "    This class wraps the worker to receive in the state a planner for a worker with multi tasks.\n",
    "    It creates worker agents based on the number of inputs and runs them asynchronously.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, worker_class, worker_name: str):\n",
    "        self.worker_class = worker_class\n",
    "        self.worker_name = worker_name\n",
    "        self.aggregator = Aggregator()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    async def run_single_task(self, task_input: Dict[str, Any], state: Dict[str, Any], \n",
    "                             config: Optional[RunnableConfig] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run a single task using a worker instance.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create a worker instance for this task\n",
    "            worker = self.worker_class()\n",
    "            \n",
    "            # Prepare state for single task\n",
    "            single_task_state = {\n",
    "                **state,\n",
    "                \"plan\": [{\"inputs\": task_input}]  # Single task plan\n",
    "            }\n",
    "            \n",
    "            # Run the worker\n",
    "            result = worker.run(single_task_state, config)\n",
    "            \n",
    "            # Extract the actual result\n",
    "            worker_result = result.get(\"last_step_result\", {})\n",
    "            final_output = worker_result.get(\"results\", {}).get(self.worker_name, \"No output\")\n",
    "            \n",
    "            return {\n",
    "                \"task\": task_input.get(\"task\", \"unknown\"),\n",
    "                \"results\": final_output,\n",
    "                \"success\": worker_result.get(\"success\", False),\n",
    "                \"error\": worker_result.get(\"error\", None)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Single task execution failed: {str(e)}\", exc_info=True)\n",
    "            return {\n",
    "                \"task\": task_input.get(\"task\", \"unknown\"),\n",
    "                \"results\": \"\",\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    async def run(self, state: Dict[str, Any], config: Optional[RunnableConfig] = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Main run method that executes multiple tasks asynchronously.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Extract inputs from the plan\n",
    "            plan_step = state[\"plan\"][0]\n",
    "            task_inputs = plan_step.get(\"inputs\", [])\n",
    "            \n",
    "            if not isinstance(task_inputs, list):\n",
    "                # Fallback for single task format\n",
    "                task_inputs = [task_inputs]\n",
    "            \n",
    "            self.logger.info(f\"{self.worker_name} received {len(task_inputs)} tasks\")\n",
    "            \n",
    "            # Create tasks for async execution\n",
    "            tasks = []\n",
    "            for task_input in task_inputs:\n",
    "                task = self.run_single_task(task_input, state, config)\n",
    "                tasks.append(task)\n",
    "            \n",
    "            # Execute all tasks asynchronously\n",
    "            task_results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            \n",
    "            # Handle any exceptions that occurred\n",
    "            processed_results = []\n",
    "            for i, result in enumerate(task_results):\n",
    "                if isinstance(result, Exception):\n",
    "                    processed_results.append({\n",
    "                        \"task\": f\"task_{i}\",\n",
    "                        \"results\": \"\",\n",
    "                        \"success\": False,\n",
    "                        \"error\": str(result)\n",
    "                    })\n",
    "                else:\n",
    "                    processed_results.append(result)\n",
    "            \n",
    "            # Aggregate results\n",
    "            return self.aggregator.aggregate_results(self.worker_name, processed_results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"{self.worker_name} multi-task execution failed: {str(e)}\", exc_info=True)\n",
    "            return {\n",
    "                \"last_step_result\": {\n",
    "                    \"worker\": self.worker_name,\n",
    "                    \"results\": {},\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e)\n",
    "                },\n",
    "                \"last_step_message\": AIMessage(\n",
    "                    content=f\"{self.worker_name} failed with error: {str(e)}\"\n",
    "                )\n",
    "            }\n",
    "\n",
    "\n",
    "class MultiWebSearchInvestigator(MultiWorker):\n",
    "    \"\"\"\n",
    "    Multi-task wrapper for WebSearchInvestigator\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(WebSearchInvestigator, \"WebSearchInvestigator\")\n",
    "\n",
    "\n",
    "class MultiImageSearchInvestigator(MultiWorker):\n",
    "    \"\"\"\n",
    "    Multi-task wrapper for ImageSearchInvestigator  \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(ImageSearchInvestigator, \"ImageSearchInvestigator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0387b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update to workers.py\n",
    "\n",
    "class EnhancedBaseWorker(BaseWorker):\n",
    "    \"\"\"Enhanced worker with step tracking and anti-repetition logic\"\"\"\n",
    "    \n",
    "    def run(self, state: Dict[str, Any], config: Optional[RunnableConfig] = None) -> Dict[str, Any]:\n",
    "        try:\n",
    "            task_input = state[\"plan\"][0][\"inputs\"]\n",
    "            task_string = task_input.get(\"task\", json.dumps(task_input))\n",
    "\n",
    "            # Prepare enhanced context\n",
    "            current_step = state.get(\"current_step\", 1)\n",
    "            max_steps = state.get(\"max_steps\", 5)\n",
    "            steps_remaining = max_steps - current_step\n",
    "            executed_tasks = state.get(\"executed_tasks\", [])\n",
    "            failed_approaches = state.get(\"failed_approaches\", [])\n",
    "\n",
    "            agg_results_str = json.dumps(state.get(\"aggregated_results\", {}), indent=2)\n",
    "            db_str = json.dumps(state.get(\"airbnb_host_data\", {}), indent=2)\n",
    "\n",
    "            result = self.agent_executor.invoke({\n",
    "                \"input\": task_string,\n",
    "                \"task\": task_string,\n",
    "                \"original_query\": state[\"original_query\"],\n",
    "                \"aggregated_results\": agg_results_str,\n",
    "                \"airbnb_host_data\": db_str,\n",
    "                \"current_step\": current_step,\n",
    "                \"max_steps\": max_steps,\n",
    "                \"steps_remaining\": steps_remaining,\n",
    "                \"executed_tasks\": executed_tasks,\n",
    "                \"failed_approaches\": failed_approaches,\n",
    "            }, config)\n",
    "\n",
    "            final_output = result.get(\"output\", f\"No specific output from {self.name}.\")\n",
    "\n",
    "            return {\n",
    "                \"last_step_result\": {\n",
    "                    \"worker\": self.name,\n",
    "                    \"results\": {self.name: final_output},\n",
    "                    \"success\": True,\n",
    "                    \"step\": current_step\n",
    "                },\n",
    "                \"last_step_message\": AIMessage(content=f\"Step {current_step}/{max_steps} - {self.name}: {final_output}\")\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"{self.name} failed: {str(e)}\", exc_info=True)\n",
    "            return {\n",
    "                \"last_step_result\": {\n",
    "                    \"worker\": self.name,\n",
    "                    \"results\": {},\n",
    "                    \"success\": False,\n",
    "                    \"error\": str(e),\n",
    "                    \"step\": state.get(\"current_step\", 1)\n",
    "                },\n",
    "                \"last_step_message\": AIMessage(content=f\"Step {state.get('current_step', 1)}/{state.get('max_steps', 5)} - {self.name} failed: {str(e)}\")\n",
    "            }\n",
    "\n",
    "# Enhanced Multi-Worker Classes\n",
    "class EnhancedMultiWebSearchInvestigator(MultiWorker):\n",
    "    def __init__(self):\n",
    "        super().__init__(lambda: EnhancedBaseWorker(\n",
    "            tools=[\n",
    "                search_tools.tavily_search, search_tools.google_search,\n",
    "                search_tools.web_scraper, search_tools.duckduckgo_search,\n",
    "                search_tools.yandex_search, search_tools.yahoo_search,\n",
    "                search_tools.baidu_search, search_tools.yelp_search,\n",
    "            ],\n",
    "            name=\"WebSearchInvestigator\",\n",
    "            system_prompt_extension=WEB_SEARCH_INVESTIGATOR_PERSONA\n",
    "        ), \"WebSearchInvestigator\")\n",
    "\n",
    "class EnhancedMultiImageSearchInvestigator(MultiWorker):\n",
    "    def __init__(self):\n",
    "        super().__init__(lambda: EnhancedBaseWorker(\n",
    "            tools=[\n",
    "                search_tools.google_lens_search,\n",
    "                search_tools.bing_images_search,\n",
    "                search_tools.google_image_search\n",
    "            ],\n",
    "            name=\"ImageSearchInvestigator\", \n",
    "            system_prompt_extension=IMAGE_SEARCH_INVESTIGATOR_PERSONA\n",
    "        ), \"ImageSearchInvestigator\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### `supervisor_prompts.py`\n",
    "\n",
    "\"\"\"\n",
    "This file contains the master prompts (the \"brains\") for the Supervisor agent.\n",
    "It defines the strategic doctrine and decision-making frameworks.\n",
    "\"\"\"\n",
    "SUPERVISOR_INITIAL_PLAN_PROMPT_ENHANCED = \"\"\"\n",
    "You are an expert OSINT investigator beginning a {max_steps}-step investigation mission.\n",
    "\n",
    "# Mission Parameters\n",
    "- **Maximum Steps**: {max_steps}\n",
    "- **Current Step**: 1 of {max_steps}\n",
    "- **Success Criteria**: Comprehensive identity profile with high confidence verification\n",
    "\n",
    "# Database Intelligence\n",
    "Here is the complete data profile for the target:\n",
    "{host_data}\n",
    "\n",
    "# Available Agents (Multi-Task Capable)\n",
    "- `multi_web_search_investigator`: Executes 2-4 complementary web searches simultaneously\n",
    "- `multi_image_search_investigator`: Executes 2-3 reverse image searches simultaneously\n",
    "\n",
    "# Strategic Planning Doctrine\n",
    "1. **Maximize Efficiency**: Each step should execute multiple complementary tasks\n",
    "2. **Intelligence Layering**: Build upon database facts with external verification\n",
    "3. **High-Probability Approaches**: Prioritize searches most likely to yield positive identification\n",
    "\n",
    "# STEP 1 STRATEGY\n",
    "Analyze the database and create 3-4 high-value initial search tasks that cover:\n",
    "- Name + location combinations\n",
    "- Unique identifiers (usernames, business names)\n",
    "- Cross-platform verification searches\n",
    "- Professional/business record searches\n",
    "\n",
    "# Output Format\n",
    "Your plan MUST be a valid JSON array with multiple complementary tasks:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"agent\": \"multi_web_search_investigator\",\n",
    "    \"inputs\": [\n",
    "      {{\"task\": \"Search for exact name and primary location combination\"}},\n",
    "      {{\"task\": \"Search for business/professional records using available identifiers\"}},\n",
    "      {{\"task\": \"Search for social media profiles using name variations and location\"}}\n",
    "    ]\n",
    "  }}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "SUPERVISOR_REASSESS_PLAN_PROMPT_ENHANCED = \"\"\"\n",
    "# ROLE & MISSION\n",
    "You are a Master OSINT (Open Source Intelligence) Strategist and Mission Commander. Your mission is to direct a team of AI specialist agents to create a comprehensive intelligence dossier on a target.\n",
    "\n",
    "# INVESTIGATIVE DOCTRINE\n",
    "1.  **Tenacity & Multi-Angle Approach**: Never stop at one piece of evidence. Use every new fact—names, usernames, locations, and URLs—to launch new waves of investigation.\n",
    "2.  **Information is Fuel**: Analyze the `aggregated_results` from your agents and the initial `airbnb_host_data` to inform your next move.\n",
    "3.  **Intelligence-Driven Tasking (SOP):**\n",
    "    - **IF** the initial `web_search_investigator` has run and `image_search_investigator` has NOT, your next step **MUST** be to deploy `image_search_investigator`. Use the `profile_pic_url` from the `airbnb_host_data`, and listenings pictures .\n",
    "    - **IF** new leads like specific social media URLs are found in `aggregated_results`, deploy `web_search_investigator` again with the `web_scraper` tool to investigate that specific URL.\n",
    "    - **IF** all leads from both web and image searches have been pursued, your final step **MUST** be to deploy `report_synthesizer`.\n",
    "\n",
    "# YOUR TEAM OF SPECIALISTS\n",
    "- `web_search_investigator`: Your primary tool for text-based searches and scraping specific URLs.\n",
    "- `image_search_investigator`: Your specialist for reverse image searches.\n",
    "- `report_synthesizer`: Deploys ONLY at the end to compile the final report.\n",
    "\n",
    "# MISSION COMMAND CENTER\n",
    "You are the Professional and the best OSINT Strategist investigator managing a {max_steps}-step investigation.\n",
    "tasks is deferent from the steps (each step contain multi tasks)\n",
    "# CURRENT STATUS:\n",
    "- **Current Step**:{current_step}\n",
    "- **Max Step**:{max_steps}\n",
    "- **Steps Remaining**:{steps_remaining}\n",
    "- **Stop Condation**: if Current Step biger then Max Step or You fined the target with the Steps Remaining last then 2.\n",
    "\n",
    "# INVESTIGATION INTELLIGENCE STATE\n",
    "- **Original Query**: {original_query}\n",
    "- **Database Intelligence**: {airbnb_host_data}\n",
    "- **Executed Tasks**: {executed_tasks}\n",
    "- **Failed Approaches**: {failed_approaches}\n",
    "- **Current Intelligence**: {aggregated_results}\n",
    "\n",
    "# STRATEGIC ASSESSMENT FRAMEWORK\n",
    "Evaluate the current state and determine the SINGLE most impactful next step:\n",
    "\n",
    "## If Steps Remaining = 0:\n",
    "- **MANDATORY**: Deploy `report_synthesizer` immediately\n",
    "## do YOUR next TASK: DYNAMIC RE-PLANNING\n",
    "Create the single next best step for the investigation.\n",
    "1.  **Handle Failures**: If the last step failed, create a new plan that works around the error. Do not repeat the failing step.\n",
    "2.  **Re-architect for Impact**: If the last step succeeded, use the new `Aggregated Findings` and the `SOP` to build the next logical mission.\n",
    "3.  **Conclude**: If all leads are exhausted, deploy `report_synthesizer`. If the report is done, return an empty JSON array `[]` to end the mission.\n",
    "\n",
    "\n",
    "# ANTI-REPETITION PROTOCOLS\n",
    "**NEVER** repeat these executed tasks: {executed_tasks}\n",
    "**AVOID** these failed approaches: {failed_approaches}\n",
    "\n",
    "# MISSION-CRITICAL DECISION TREE\n",
    "1. **IMAGE SEARCH PRIORITY**: If web searches completed but no image searches executed → Deploy `multi_image_search_investigator`\n",
    "2. **WEB FOLLOW-UP**: If new URLs/profiles discovered → Deploy targeted `multi_web_search_investigator`\n",
    "3. **FINALIZATION**: If investigation complete or steps exhausted → Deploy `report_synthesizer`\n",
    "\n",
    "# OUTPUT FORMAT\n",
    "Return a JSON array with a SINGLE step containing multiple strategic tasks:\n",
    "\n",
    "For multi-task operations:\n",
    "[\n",
    "  {{\n",
    "    \"agent\": \"multi_web_search_investigator\",\n",
    "    \"inputs\": [\n",
    "      {{\"task\": \"NEW high-value task based on current intelligence\"}},\n",
    "      {{\"task\": \"Follow-up investigation on discovered leads\"}},\n",
    "      {{\"task\": \"Verification search for identified profiles\"}}\n",
    "    ]\n",
    "  }}\n",
    "]\n",
    "\n",
    "For finalization:\n",
    "[\n",
    "  {{\n",
    "    \"agent\": \"report_synthesizer\",\n",
    "    \"inputs\": {{}}\n",
    "  }}\n",
    "]\n",
    "\n",
    "For mission completion:\n",
    "[]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SUPERVISOR_INITIAL_PLAN_PROMPT = \"\"\"\n",
    "You are an expert OSINT investigator kicking off a new mission. Your first job is to create the single, most effective first step for your team based on data extracted from an internal database.\n",
    "\n",
    "# Mission Objective\n",
    "Analyze the provided Airbnb host data and create the best first task for your team.\n",
    "\n",
    "# Database Intelligence\n",
    "Here is the complete data profile for the target, extracted from our database:\n",
    "{host_data}\n",
    "\n",
    "# Available Agents\n",
    "- `web_search_investigator`: Conducts web searches for names, locations, etc.\n",
    "- `image_search_investigator`: Conducts reverse image searches on URLs.\n",
    "\n",
    "# Standard Operating Procedure (SOP) for Initial Tasking\n",
    "1.  **Analyze**: Meticulously analyze the `host_data` to identify the host's name, primary location, and profile picture URL.\n",
    "2.  **Prioritize**: The highest-value first step is almost always a targeted web search.\n",
    "3.  **Task Creation**: Your first and only step in the plan MUST be to deploy the `web_search_investigator`.\n",
    "4.  **Construct Query**: Create a precise task for the agent. For example, if the host is named \"Abdel\" and is from \"Marrakech\", the input should be `{{ \"task\": \"Search for 'Abdel from Marrakech' to find social media profiles and business records.\" }}`.\n",
    "\n",
    "# Output Format\n",
    "Your plan MUST be a valid JSON array containing a single step for the `web_search_investigator`.\n",
    "\n",
    "Example:\n",
    "[\n",
    "  {{\n",
    "    \"agent\": \"agent_name\",\n",
    "    \"inputs\": {{\n",
    "      \"task\": \"task details for maximaize the oportenity of find the target and finish investigation\"\n",
    "    }}\n",
    "  }}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SUPERVISOR_REASSESS_PLAN_PROMPT = \"\"\"\n",
    "# ROLE & MISSION\n",
    "You are a Master OSINT (Open Source Intelligence) Strategist and Mission Commander. Your mission is to direct a team of AI specialist agents to create a comprehensive intelligence dossier on a target.\n",
    "\n",
    "# INVESTIGATIVE DOCTRINE\n",
    "1.  **Tenacity & Multi-Angle Approach**: Never stop at one piece of evidence. Use every new fact—names, usernames, locations, and URLs—to launch new waves of investigation.\n",
    "2.  **Information is Fuel**: Analyze the `aggregated_results` from your agents and the initial `airbnb_host_data` to inform your next move.\n",
    "3.  **Intelligence-Driven Tasking (SOP):**\n",
    "    - **IF** the initial `web_search_investigator` has run and `image_search_investigator` has NOT, your next step **MUST** be to deploy `image_search_investigator`. Use the `profile_pic_url` from the `airbnb_host_data`, and listenings pictures .\n",
    "    - **IF** new leads like specific social media URLs are found in `aggregated_results`, deploy `web_search_investigator` again with the `web_scraper` tool to investigate that specific URL.\n",
    "    - **IF** all leads from both web and image searches have been pursued, your final step **MUST** be to deploy `report_synthesizer`.\n",
    "\n",
    "# YOUR TEAM OF SPECIALISTS\n",
    "- `web_search_investigator`: Your primary tool for text-based searches and scraping specific URLs.\n",
    "- `image_search_investigator`: Your specialist for reverse image searches.\n",
    "- `report_synthesizer`: Deploys ONLY at the end to compile the final report.\n",
    "\n",
    "# CURRENT INVESTIGATION STATE\n",
    "- **Original Query**: {original_query}\n",
    "- **Initial DB Intelligence**: {airbnb_host_data}\n",
    "- **Completed Steps & Results**: {past_steps}\n",
    "- **Aggregated Findings (Latest Intelligence)**: {aggregated_results}\n",
    "\n",
    "# YOUR TASK: DYNAMIC RE-PLANNING\n",
    "Create the single next best step for the investigation.\n",
    "1.  **Handle Failures**: If the last step failed, create a new plan that works around the error. Do not repeat the failing step.\n",
    "2.  **Re-architect for Impact**: If the last step succeeded, use the new `Aggregated Findings` and the `SOP` to build the next logical mission.\n",
    "3.  **Conclude**: If all leads are exhausted, deploy `report_synthesizer`. If the report is done, return an empty JSON array `[]` to end the mission.\n",
    "\n",
    "# OUTPUT FORMAT & RULES\n",
    "Your response MUST be a valid JSON array containing a SINGLE step.\n",
    "- Do NOT output any other text or explanations.\n",
    "\n",
    "Example for [`image_search_investigator`, `web_search_investigator`]:\n",
    "[\n",
    "  {{\n",
    "    \"agent\": \"agent_name\",\n",
    "    \"inputs\": {{\n",
    "      \"task\": \"task details for maximaize the oportenity of find the target and finish investigation\"\n",
    "    }}\n",
    "  }}\n",
    "]\n",
    "\n",
    "\n",
    "Example for `report_synthesizer`:\n",
    "[\n",
    "  {{\n",
    "    \"agent\": \"report_synthesizer\",\n",
    "    \"inputs\": {{}}\n",
    "  }}\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be148f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Supervisor Prompts to handle multi-task planning\n",
    "\n",
    "SUPERVISOR_INITIAL_PLAN_PROMPT_MULTI = \"\"\"\n",
    "You are an expert OSINT investigator kicking off a new mission. Your first job is to create multiple effective tasks for your team based on data extracted from an internal database.\n",
    "\n",
    "# Mission Objective\n",
    "Analyze the provided Airbnb host data and create the best initial tasks for your team.\n",
    "\n",
    "# Database Intelligence\n",
    "Here is the complete data profile for the target, extracted from our database:\n",
    "{host_data}\n",
    "\n",
    "# Available Agents\n",
    "- `multi_web_search_investigator`: Conducts multiple web searches simultaneously\n",
    "- `multi_image_search_investigator`: Conducts multiple reverse image searches simultaneously\n",
    "\n",
    "# Standard Operating Procedure (SOP) for Initial Tasking\n",
    "1. **Analyze**: Meticulously analyze the `host_data` to identify the host's name, primary location, profile picture URL, and other identifying information.\n",
    "2. **Multi-Task Strategy**: Create 2-4 complementary search tasks that cover different angles of investigation.\n",
    "3. **Task Creation**: Your first step should deploy the `multi_web_search_investigator` with multiple targeted searches.\n",
    "4. **Construct Queries**: Create precise tasks. For example, if the host is named \"Abdel\" from \"Marrakech\":\n",
    "   - Search for the full name and location\n",
    "   - Search for business records \n",
    "   - Search for social media profiles\n",
    "   - Search for any unique identifiers found in the data\n",
    "\n",
    "# Output Format\n",
    "Your plan MUST be a valid JSON array containing a single step with multiple inputs for the worker.\n",
    "\n",
    "Example:\n",
    "[\n",
    "  {{\n",
    "    \"agent\": \"multi_web_search_investigator\",\n",
    "    \"inputs\": [\n",
    "      {{\"task\": \"Search for 'Abdel from Marrakech' to find social media profiles\"}},\n",
    "      {{\"task\": \"Search for 'Abdel Marrakech business' to find professional records\"}},\n",
    "      {{\"task\": \"Search for any unique usernames or identifiers found in the host data\"}}\n",
    "    ]\n",
    "  }}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "SUPERVISOR_REASSESS_PLAN_PROMPT_MULTI = \"\"\"\n",
    "# ROLE & MISSION\n",
    "You are a Master OSINT (Open Source Intelligence) Strategist and Mission Commander. Your mission is to direct a team of AI specialist agents to create a comprehensive intelligence dossier on a target.\n",
    "\n",
    "# INVESTIGATIVE DOCTRINE\n",
    "1. **Tenacity & Multi-Angle Approach**: Never stop at one piece of evidence. Use every new fact—names, usernames, locations, and URLs—to launch new waves of investigation.\n",
    "2. **Information is Fuel**: Analyze the `aggregated_results` from your agents and the initial `airbnb_host_data` to inform your next move.\n",
    "3. **Multi-Task Intelligence-Driven Tasking (SOP):**\n",
    "   - **IF** initial web searches completed and image search hasn't run, deploy `multi_image_search_investigator` with multiple image tasks\n",
    "   - **IF** new leads like specific URLs are found, deploy `multi_web_search_investigator` again with targeted scraping tasks\n",
    "   - **IF** all leads have been pursued, deploy `report_synthesizer`\n",
    "\n",
    "# YOUR TEAM OF SPECIALISTS\n",
    "- `multi_web_search_investigator`: Executes multiple web searches and scraping tasks simultaneously\n",
    "- `multi_image_search_investigator`: Executes multiple reverse image searches simultaneously  \n",
    "- `report_synthesizer`: Compiles the final report (single task only)\n",
    "\n",
    "# CURRENT INVESTIGATION STATE\n",
    "- **Original Query**: {original_query}\n",
    "- **Initial DB Intelligence**: {airbnb_host_data}\n",
    "- **Completed Steps & Results**: {past_steps}\n",
    "- **Aggregated Findings (Latest Intelligence)**: {aggregated_results}\n",
    "\n",
    "# YOUR TASK: DYNAMIC RE-PLANNING\n",
    "Create the single next best step with multiple tasks for maximum investigation efficiency.\n",
    "\n",
    "# OUTPUT FORMAT & RULES\n",
    "Your response MUST be a valid JSON array containing a SINGLE step with multiple inputs.\n",
    "\n",
    "Example for multi-task agents:\n",
    "[\n",
    "  {{\n",
    "    \"agent\": \"multi_web_search_investigator\", \n",
    "    \"inputs\": [\n",
    "      {{\"task\": \"Scrape and analyze the Facebook profile found: [URL]\"}},\n",
    "      {{\"task\": \"Search for additional social media using the real name discovered\"}},\n",
    "      {{\"task\": \"Investigate the business connections mentioned in previous results\"}}\n",
    "    ]\n",
    "  }}\n",
    "]\n",
    "\n",
    "Example for report synthesizer (single task):\n",
    "[\n",
    "  {{\n",
    "    \"agent\": \"report_synthesizer\",\n",
    "    \"inputs\": {{}}\n",
    "  }}\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional, cast\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from multi_agents.constants.constants import Constants\n",
    "from multi_agents.agents.workers import AirbnbAnalyzer\n",
    "import logging\n",
    "from pydantic import SecretStr\n",
    "import json\n",
    "import re\n",
    "from multi_agents.database.airbnb_db import AirbnbDB\n",
    "\n",
    "\n",
    "# from multi_agents.Prompts.supervisor_prompts import (\n",
    "#     SUPERVISOR_INITIAL_PLAN_PROMPT,\n",
    "#     SUPERVISOR_REASSESS_PLAN_PROMPT,\n",
    "# )\n",
    "# from ..graph.state import AgentState\n",
    "\n",
    "class Supervisor:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=Constants.SUPERVISOR_MODEL,\n",
    "            temperature=0.0,\n",
    "            base_url=Constants.OPENROUTER_BASE_URL,\n",
    "            api_key=SecretStr(Constants.OPENROUTER_API_KEY or \"\")\n",
    "        )\n",
    "        self.parser = JsonOutputParser()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.db_path = Constants.CONFIG_DB_FILE\n",
    "\n",
    "        self.retrival = AirbnbAnalyzer()._tool_get_host_all\n",
    "\n",
    "    # --- Database Extraction Logic (migrated from old AirbnbAnalyzer) ---\n",
    "    def _db(self) -> AirbnbDB:\n",
    "        # fresh connection per call => avoids cross-thread sqlite issues\n",
    "        return AirbnbDB(self.db_path)\n",
    "\n",
    "    def _parse_user_id(self, s: str) -> Optional[str]:\n",
    "        if not s:\n",
    "            return None\n",
    "        if s.isdigit():\n",
    "            return s\n",
    "        m = re.search(r\"/users/show/(\\d+)\", s)\n",
    "        return m.group(1) if m else None\n",
    "\n",
    "    def _fetch_profile(self, db: AirbnbDB, host: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Robustly fetches host profile by ID or URL with fallbacks.\"\"\"\n",
    "        user_id = self._parse_user_id(host)\n",
    "\n",
    "        if user_id:\n",
    "            try:\n",
    "                cur = db.conn.execute(\"SELECT * FROM host_tracking WHERE userId = ? ORDER BY rowid DESC LIMIT 1\", (user_id,))\n",
    "                r = cur.fetchone()\n",
    "                if r: return dict(r)\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"host_tracking by userId failed: {e}\")\n",
    "\n",
    "        if host and host.startswith(\"http\"):\n",
    "            try:\n",
    "                cur = db.conn.execute(\"SELECT * FROM host_tracking WHERE userUrl = ? ORDER BY rowid DESC LIMIT 1\", (host,))\n",
    "                r = cur.fetchone()\n",
    "                if r: return dict(r)\n",
    "            except Exception as e:\n",
    "                self.logger.warning(f\"host_tracking by userUrl failed: {e}\")\n",
    "        return None\n",
    "\n",
    "    def _listings(self, db: AirbnbDB, uid: str) -> List[Dict[str, Any]]:\n",
    "        try:\n",
    "            cur = db.conn.execute(\"SELECT userId, name, listingId, listingUrl FROM host_listings WHERE userId = ? ORDER BY rowid DESC\", (uid,))\n",
    "            return [dict(row) for row in cur.fetchall()]\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "    def _listings_detailed(self, db: AirbnbDB, uid: str) -> List[Dict[str, Any]]:\n",
    "        try:\n",
    "            cur = db.conn.execute(\"SELECT * FROM listing_tracking WHERE userId = ? ORDER BY rowid DESC\", (uid,))\n",
    "            return [dict(row) for row in cur.fetchall()]\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "    def _reviews_all(self, db: AirbnbDB, uid: str) -> List[Dict[str, Any]]:\n",
    "        try:\n",
    "            cur = db.conn.execute(\"SELECT * FROM host_reviews WHERE userId = ? ORDER BY id ASC\", (uid,))\n",
    "            return [dict(row) for row in cur.fetchall()]\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "    def _dedupe_reviews(self, rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        seen = set()\n",
    "        out = []\n",
    "        for r in rows:\n",
    "            key = (r.get(\"reviewer_name\", \"\"), (r.get(\"text\") or \"\").strip())\n",
    "            if key in seen: continue\n",
    "            seen.add(key)\n",
    "            out.append(r)\n",
    "        return out\n",
    "\n",
    "    def _get_host_all_data(self, host_identifier: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        DB-only: given a host id or profile URL, pull EVERYTHING we have for that host from SQLite.\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Attempting to extract all DB data for host: {host_identifier}\")\n",
    "        try:\n",
    "            host = host_identifier.strip()\n",
    "            db = self._db()\n",
    "\n",
    "            profile = self._fetch_profile(db, host)\n",
    "            if not profile:\n",
    "                return {\"status\": \"error_not_found\", \"reason\": \"host_not_in_db\", \"input\": host}\n",
    "\n",
    "            uid = str(profile.get(\"userId\") or \"\")\n",
    "            if not uid:\n",
    "                 return {\"status\": \"error_not_found\", \"reason\": \"Could not determine userId from profile\", \"profile\": profile}\n",
    "\n",
    "\n",
    "            listings = self._listings(db, uid)\n",
    "            listings_detailed = self._listings_detailed(db, uid)\n",
    "            reviews_raw = self._reviews_all(db, uid) or []\n",
    "            reviews = self._dedupe_reviews(reviews_raw)\n",
    "\n",
    "            return {\n",
    "                \"status\": \"ok\",\n",
    "                \"userId\": uid,\n",
    "                \"core\": profile,\n",
    "                \"listings\": listings,\n",
    "                \"listings_detailed\": listings_detailed,\n",
    "                \"reviews\": reviews,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Database extraction failed for host '{host_identifier}': {e}\", exc_info=True)\n",
    "            return {\"status\": \"error\", \"error\": str(e)}\n",
    "\n",
    "    # --- End of Corrected Database Extraction Logic ---\n",
    "\n",
    "\n",
    "    # --- Planning Logic ---\n",
    "    def create_initial_plan(self, host_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate initial investigation plan based on DB data.\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(SUPERVISOR_INITIAL_PLAN_PROMPT)\n",
    "        chain = prompt | self.llm | self.parser\n",
    "        try:\n",
    "            # Serialize data for the prompt\n",
    "            host_data_str = json.dumps(host_data, indent=2)\n",
    "            plan = chain.invoke({\"host_data\": host_data_str})\n",
    "            self.logger.info(f\"Initial plan created: {plan}\")\n",
    "            return cast(List[Dict[str, Any]], plan)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to create initial plan: {e}\")\n",
    "            # Fallback plan\n",
    "            return [{\"agent\": \"web_search_investigator\", \"inputs\": {\"task\": \"General search for the target.\"}}]\n",
    "\n",
    "    def reassess_plan(self, state: AgentState) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Re-evaluates and updates the investigation plan.\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(SUPERVISOR_REASSESS_PLAN_PROMPT)\n",
    "        chain = prompt | self.llm | self.parser\n",
    "        try:\n",
    "            # Serialize complex objects for the prompt\n",
    "            state_for_prompt = {\n",
    "                **state,\n",
    "                \"airbnb_host_data\": json.dumps(state.get(\"airbnb_host_data\"), indent=2),\n",
    "                \"aggregated_results\": json.dumps(state.get(\"aggregated_results\"), indent=2),\n",
    "                \"past_steps\": json.dumps(state.get(\"past_steps\"), indent=2)\n",
    "            }\n",
    "            new_plan = chain.invoke(state_for_prompt)\n",
    "            self.logger.info(f\"Supervisor re-architected the plan: {new_plan}\")\n",
    "            return cast(List[Dict[str, Any]], new_plan)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Critical failure during plan reassessment: {e}\")\n",
    "            return [] # End the investigation on planning failure\n",
    "\n",
    "    # --- Router ---\n",
    "    def route_to_worker(self, state: AgentState) -> str:\n",
    "        if not state.get(\"plan\"):\n",
    "            return \"end\"\n",
    "        next_agent = state[\"plan\"][0].get(\"agent\")\n",
    "        if not next_agent:\n",
    "            self.logger.warning(\"No agent specified in plan step, ending.\")\n",
    "            return \"end\"\n",
    "        return next_agent\n",
    "\n",
    "    # --- Main Entry Point for the Graph ---\n",
    "    def run(self, state: AgentState, config: Optional[Any] = None) -> Dict[str, Any]:\n",
    "        # --- First Run Initialization ---\n",
    "        if \"plan\" not in state or state.get(\"plan\") is None:\n",
    "            self.logger.info(\"Supervisor running for the first time. Initializing investigation.\")\n",
    "            try:\n",
    "                host_data = self.retrival(\n",
    "                    {\"host\": self._get_host_all_data(state[\"original_query\"])}\n",
    "                )                                                                                    # self._get_host_all_data(state[\"original_query\"])\n",
    "                if host_data.get(\"status\") != \"ok\":\n",
    "                     return {\"messages\": [AIMessage(content=f\"Fatal Error: Could not extract initial data from DB. Reason: {host_data.get('reason') or host_data.get('error')}\")]}\n",
    "            except Exception as e:\n",
    "                return {\"messages\": [AIMessage(content=f\"Fatal Error: An exception occurred during DB extraction. {e}\")]}\n",
    "\n",
    "            plan = self.create_initial_plan(host_data)\n",
    "            return {\n",
    "                \"plan\": plan,\n",
    "                \"airbnb_host_data\": host_data,\n",
    "                \"past_steps\": [],\n",
    "                \"aggregated_results\": {},\n",
    "                \"messages\": [AIMessage(content=\"Extracted host data from database and created initial investigation plan.\")]\n",
    "            }\n",
    "\n",
    "        # --- Subsequent Runs: Process last result and re-plan ---\n",
    "        last_result = state.get(\"last_step_result\")\n",
    "        if last_result:\n",
    "            # Update history and aggregated findings\n",
    "            new_past_steps = state.get(\"past_steps\", []) + [last_result]\n",
    "            new_aggregated_results = {**state.get(\"aggregated_results\", {}), **last_result.get(\"results\", {})}\n",
    "\n",
    "            # Create a temporary state to pass to the planner\n",
    "            temp_state_for_planning = cast(AgentState, {\n",
    "                **state,\n",
    "                \"past_steps\": new_past_steps,\n",
    "                \"aggregated_results\": new_aggregated_results\n",
    "            })\n",
    "\n",
    "            # Re-plan based on the new information\n",
    "            new_plan = self.reassess_plan(temp_state_for_planning)\n",
    "\n",
    "            return {\n",
    "                \"plan\": new_plan,\n",
    "                \"past_steps\": new_past_steps,\n",
    "                \"aggregated_results\": new_aggregated_results,\n",
    "                \"messages\": state.get(\"messages\", []) + [cast(AIMessage, state.get(\"last_step_message\"))],\n",
    "                \"last_step_result\": None, # Clear transient state\n",
    "                \"last_step_message\": None\n",
    "            }\n",
    "\n",
    "        # Should not be reached in normal flow\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Updated Supervisor class methods\n",
    "\n",
    "class SupervisorMulti(Supervisor):\n",
    "    \"\"\"\n",
    "    Updated Supervisor that handles multi-task planning\n",
    "    \"\"\"\n",
    "    \n",
    "    def create_initial_plan(self, host_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate initial investigation plan with multiple tasks based on DB data.\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(SUPERVISOR_INITIAL_PLAN_PROMPT_MULTI)\n",
    "        chain = prompt | self.llm | self.parser\n",
    "        try:\n",
    "            host_data_str = json.dumps(host_data, indent=2)\n",
    "            plan = chain.invoke({\"host_data\": host_data_str})\n",
    "            self.logger.info(f\"Multi-task initial plan created: {plan}\")\n",
    "            return cast(List[Dict[str, Any]], plan)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to create initial multi-task plan: {e}\")\n",
    "            # Fallback plan with multiple tasks\n",
    "            return [{\n",
    "                \"agent\": \"multi_web_search_investigator\", \n",
    "                \"inputs\": [\n",
    "                    {\"task\": \"General search for the target\"},\n",
    "                    {\"task\": \"Search for social media profiles\"},\n",
    "                    {\"task\": \"Search for business records\"}\n",
    "                ]\n",
    "            }]\n",
    "\n",
    "    def reassess_plan(self, state: AgentState) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Re-evaluates and updates the investigation plan with multi-task support.\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(SUPERVISOR_REASSESS_PLAN_PROMPT_MULTI)\n",
    "        chain = prompt | self.llm | self.parser\n",
    "        try:\n",
    "            state_for_prompt = {\n",
    "                **state,\n",
    "                \"airbnb_host_data\": json.dumps(state.get(\"airbnb_host_data\"), indent=2),\n",
    "                \"aggregated_results\": json.dumps(state.get(\"aggregated_results\"), indent=2),\n",
    "                \"past_steps\": json.dumps(state.get(\"past_steps\"), indent=2)\n",
    "            }\n",
    "            new_plan = chain.invoke(state_for_prompt)\n",
    "            self.logger.info(f\"Supervisor re-architected the multi-task plan: {new_plan}\")\n",
    "            return cast(List[Dict[str, Any]], new_plan)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Critical failure during multi-task plan reassessment: {e}\")\n",
    "            return []\n",
    "\n",
    "    def route_to_worker(self, state: AgentState) -> str:\n",
    "        \"\"\"Updated router to handle multi-worker agents\"\"\"\n",
    "        if not state.get(\"plan\"):\n",
    "            return \"end\"\n",
    "        next_agent = state[\"plan\"][0].get(\"agent\")\n",
    "        if not next_agent:\n",
    "            self.logger.warning(\"No agent specified in plan step, ending.\")\n",
    "            return \"end\"\n",
    "        \n",
    "        # Map to multi-worker versions\n",
    "        agent_mapping = {\n",
    "            \"web_search_investigator\": \"multi_web_search_investigator\",\n",
    "            \"image_search_investigator\": \"multi_image_search_investigator\",\n",
    "            \"multi_web_search_investigator\": \"multi_web_search_investigator\", \n",
    "            \"multi_image_search_investigator\": \"multi_image_search_investigator\",\n",
    "            \"report_synthesizer\": \"report_synthesizer\"\n",
    "        }\n",
    "        \n",
    "        return agent_mapping.get(next_agent, next_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12dec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedSupervisorMulti(SupervisorMulti):\n",
    "    \"\"\"\n",
    "    Enhanced Supervisor with step tracking and anti-repetition logic\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_steps: int = 5):\n",
    "        super().__init__()\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "    def _extract_task_signatures(self, executed_steps: List[Dict[str, Any]]) -> List[str]:\n",
    "        \"\"\"Extract unique task signatures to avoid repetition\"\"\"\n",
    "        signatures = []\n",
    "        for step in executed_steps:\n",
    "            worker = step.get(\"worker\", \"\")\n",
    "            if \"WebSearch\" in worker:\n",
    "                # Extract search terms/concepts\n",
    "                results = step.get(\"results\", {})\n",
    "                for key, value in results.items():\n",
    "                    if isinstance(value, str) and len(value) > 20:\n",
    "                        # Extract key search concepts (simplified)\n",
    "                        if \"search\" in key.lower():\n",
    "                            signatures.append(f\"web_search:{key[:50]}\")\n",
    "            elif \"ImageSearch\" in worker:\n",
    "                signatures.append(\"image_search:profile_pic\")\n",
    "        return signatures\n",
    "\n",
    "    def _extract_failed_approaches(self, executed_steps: List[Dict[str, Any]]) -> List[str]:\n",
    "        \"\"\"Extract approaches that failed to avoid repetition\"\"\"\n",
    "        failed = []\n",
    "        for step in executed_steps:\n",
    "            if not step.get(\"success\", True):\n",
    "                worker = step.get(\"worker\", \"\")\n",
    "                error = step.get(\"error\", \"\")\n",
    "                failed.append(f\"{worker}:{error[:100]}\")\n",
    "        return failed\n",
    "\n",
    "    def create_initial_plan(self, host_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Generate initial investigation plan with step awareness\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(SUPERVISOR_INITIAL_PLAN_PROMPT_ENHANCED)\n",
    "        chain = prompt | self.llm | self.parser\n",
    "        try:\n",
    "            host_data_str = json.dumps(host_data, indent=2)\n",
    "            plan = chain.invoke({\n",
    "                \"host_data\": host_data_str,\n",
    "                \"max_steps\": self.max_steps\n",
    "            })\n",
    "            self.logger.info(f\"Enhanced initial plan created: {plan}\")\n",
    "            return cast(List[Dict[str, Any]], plan)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to create enhanced initial plan: {e}\")\n",
    "            return [{\n",
    "                \"agent\": \"multi_web_search_investigator\",\n",
    "                \"inputs\": [\n",
    "                    {\"task\": \"Comprehensive name and location search\"},\n",
    "                    {\"task\": \"Social media profile discovery\"},\n",
    "                    {\"task\": \"Business record verification\"}\n",
    "                ]\n",
    "            }]\n",
    "\n",
    "    def reassess_plan(self, state: AgentState) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Enhanced plan reassessment with step awareness\"\"\"\n",
    "        current_step = state.get(\"current_step\", 1)\n",
    "        steps_remaining = self.max_steps - current_step\n",
    "        executed_tasks = self._extract_task_signatures(state.get(\"past_steps\", []))\n",
    "        failed_approaches = self._extract_failed_approaches(state.get(\"past_steps\", []))\n",
    "\n",
    "        # Force report synthesis if steps exhausted\n",
    "        if steps_remaining <= 0:\n",
    "            return [{\"agent\": \"report_synthesizer\", \"inputs\": {}}]\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_template(SUPERVISOR_REASSESS_PLAN_PROMPT_ENHANCED)\n",
    "        chain = prompt | self.llm | self.parser\n",
    "        try:\n",
    "            state_for_prompt = {\n",
    "                **state,\n",
    "                \"airbnb_host_data\": json.dumps(state.get(\"airbnb_host_data\"), indent=2),\n",
    "                \"aggregated_results\": json.dumps(state.get(\"aggregated_results\"), indent=2),\n",
    "                \"current_step\": current_step + 1,\n",
    "                \"max_steps\": self.max_steps,\n",
    "                \"steps_remaining\": steps_remaining,\n",
    "                \"executed_tasks\": executed_tasks,\n",
    "                \"failed_approaches\": failed_approaches\n",
    "            }\n",
    "            new_plan = chain.invoke(state_for_prompt)\n",
    "            self.logger.info(f\"Enhanced plan reassessment: Step {current_step + 1}/{self.max_steps}, Plan: {new_plan}\")\n",
    "            return cast(List[Dict[str, Any]], new_plan)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Enhanced plan reassessment failed: {e}\")\n",
    "            # Force completion if planning fails\n",
    "            return [{\"agent\": \"report_synthesizer\", \"inputs\": {}}]\n",
    "\n",
    "    def run(self, state: AgentState, config: Optional[Any] = None) -> Dict[str, Any]:\n",
    "        # Initialize step tracking on first run\n",
    "        if \"current_step\" not in state:\n",
    "            state = {\n",
    "                **state,\n",
    "                \"current_step\": 0,\n",
    "                \"max_steps\": self.max_steps,\n",
    "                \"executed_tasks\": [],\n",
    "                \"failed_approaches\": []\n",
    "            }\n",
    "\n",
    "        # First run initialization\n",
    "        if \"plan\" not in state or state.get(\"plan\") is None:\n",
    "            self.logger.info(f\"Starting {self.max_steps}-step OSINT investigation\")\n",
    "            try:\n",
    "                host_data = self.retrival(\n",
    "                    {\"host\": self._get_host_all_data(state[\"original_query\"])}\n",
    "                )\n",
    "                if host_data.get(\"status\") != \"ok\":\n",
    "                    return {\"messages\": [AIMessage(content=f\"Fatal Error: Could not extract initial data from DB. Reason: {host_data.get('reason') or host_data.get('error')}\")]}\n",
    "            except Exception as e:\n",
    "                return {\"messages\": [AIMessage(content=f\"Fatal Error: DB extraction failed. {e}\")]}\n",
    "\n",
    "            plan = self.create_initial_plan(host_data)\n",
    "            return {\n",
    "                **state,\n",
    "                \"plan\": plan,\n",
    "                \"airbnb_host_data\": host_data,\n",
    "                \"current_step\": 1,\n",
    "                \"past_steps\": [],\n",
    "                \"aggregated_results\": {},\n",
    "                \"messages\": [AIMessage(content=f\"Initialized {self.max_steps}-step OSINT investigation with database intelligence.\")]\n",
    "            }\n",
    "\n",
    "        # Process results and increment step counter\n",
    "        last_result = state.get(\"last_step_result\")\n",
    "        if last_result:\n",
    "            new_current_step = state.get(\"current_step\", 1) + 1\n",
    "            new_past_steps = state.get(\"past_steps\", []) + [last_result]\n",
    "            new_aggregated_results = {**state.get(\"aggregated_results\", {}), **last_result.get(\"results\", {})}\n",
    "            \n",
    "            # Update task tracking\n",
    "            executed_tasks = state.get(\"executed_tasks\", [])\n",
    "            if not last_result.get(\"success\", True):\n",
    "                failed_approaches = state.get(\"failed_approaches\", [])\n",
    "                failed_approaches.append(f\"Step{new_current_step-1}:{last_result.get('worker', 'unknown')}\")\n",
    "            else:\n",
    "                failed_approaches = state.get(\"failed_approaches\", [])\n",
    "\n",
    "            # Create temporary state for planning\n",
    "            temp_state_for_planning = cast(AgentState, {\n",
    "                **state,\n",
    "                \"current_step\": new_current_step,\n",
    "                \"past_steps\": new_past_steps,\n",
    "                \"aggregated_results\": new_aggregated_results,\n",
    "                \"executed_tasks\": executed_tasks,\n",
    "                \"failed_approaches\": failed_approaches\n",
    "            })\n",
    "\n",
    "            # Re-plan with step awareness\n",
    "            new_plan = self.reassess_plan(temp_state_for_planning)\n",
    "\n",
    "            return {\n",
    "                **state,\n",
    "                \"plan\": new_plan,\n",
    "                \"current_step\": new_current_step,\n",
    "                \"past_steps\": new_past_steps,\n",
    "                \"aggregated_results\": new_aggregated_results,\n",
    "                \"executed_tasks\": executed_tasks,\n",
    "                \"failed_approaches\": failed_approaches,\n",
    "                \"messages\": state.get(\"messages\", []) + [cast(AIMessage, state.get(\"last_step_message\"))],\n",
    "                \"last_step_result\": None,\n",
    "                \"last_step_message\": None\n",
    "            }\n",
    "\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db414d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.pregel import Pregel\n",
    "# from .state import AgentState\n",
    "# from ..agents.supervisor import Supervisor\n",
    "# from ..agents.workers import (\n",
    "#     WebSearchInvestigator,\n",
    "#     ImageSearchInvestigator,\n",
    "#     ReportSynthesizer\n",
    "# )\n",
    "\n",
    "class GraphBuilder:\n",
    "    def __init__(self):\n",
    "        self.supervisor = Supervisor()\n",
    "        self.web_search_investigator = WebSearchInvestigator()\n",
    "        self.image_search_investigator = ImageSearchInvestigator()\n",
    "        self.report_synthesizer = ReportSynthesizer()\n",
    "\n",
    "    def build_graph(self) -> Pregel:\n",
    "        workflow = StateGraph(AgentState)\n",
    "\n",
    "        # Add nodes\n",
    "        workflow.add_node(\"supervisor\", self.supervisor.run)\n",
    "        workflow.add_node(\"web_search_investigator\", self.web_search_investigator.run)\n",
    "        workflow.add_node(\"image_search_investigator\", self.image_search_investigator.run)\n",
    "        workflow.add_node(\"report_synthesizer\", self.report_synthesizer.run)\n",
    "\n",
    "        # Define edges\n",
    "        workflow.add_edge(\"web_search_investigator\", \"supervisor\")\n",
    "        workflow.add_edge(\"image_search_investigator\", \"supervisor\")\n",
    "        workflow.add_edge(\"report_synthesizer\", END)\n",
    "\n",
    "        # Conditional edges from supervisor\n",
    "        workflow.add_conditional_edges(\n",
    "            \"supervisor\",\n",
    "            self.supervisor.route_to_worker,\n",
    "            {\n",
    "                \"web_search_investigator\": \"web_search_investigator\",\n",
    "                \"image_search_investigator\": \"image_search_investigator\",\n",
    "                \"report_synthesizer\": \"report_synthesizer\",\n",
    "                \"end\": END\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Set entry point\n",
    "        workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "        return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c487da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Graph Builder\n",
    "\n",
    "class MultiGraphBuilder:\n",
    "    def __init__(self):\n",
    "        self.supervisor = SupervisorMulti()\n",
    "        self.multi_web_search_investigator = MultiWebSearchInvestigator()\n",
    "        self.multi_image_search_investigator = MultiImageSearchInvestigator()\n",
    "        self.report_synthesizer = ReportSynthesizer()\n",
    "\n",
    "    def build_graph(self) -> Pregel:\n",
    "        workflow = StateGraph(AgentState)\n",
    "\n",
    "        # Add nodes - now with multi-worker support\n",
    "        workflow.add_node(\"supervisor\", self.supervisor.run)\n",
    "        workflow.add_node(\"multi_web_search_investigator\", self.multi_web_search_investigator.run)\n",
    "        workflow.add_node(\"multi_image_search_investigator\", self.multi_image_search_investigator.run)\n",
    "        workflow.add_node(\"report_synthesizer\", self.report_synthesizer.run)\n",
    "\n",
    "        # Define edges\n",
    "        workflow.add_edge(\"multi_web_search_investigator\", \"supervisor\")\n",
    "        workflow.add_edge(\"multi_image_search_investigator\", \"supervisor\")\n",
    "        workflow.add_edge(\"report_synthesizer\", END)\n",
    "\n",
    "        # Conditional edges from supervisor\n",
    "        workflow.add_conditional_edges(\n",
    "            \"supervisor\",\n",
    "            self.supervisor.route_to_worker,\n",
    "            {\n",
    "                \"multi_web_search_investigator\": \"multi_web_search_investigator\",\n",
    "                \"multi_image_search_investigator\": \"multi_image_search_investigator\",\n",
    "                \"report_synthesizer\": \"report_synthesizer\",\n",
    "                \"end\": END\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Set entry point\n",
    "        workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "        return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Graph Builder\n",
    "# Update to builder.py\n",
    "\n",
    "class EnhancedMultiGraphBuilder:\n",
    "    def __init__(self, max_steps: int = 5):\n",
    "        self.supervisor = EnhancedSupervisorMulti(max_steps=max_steps)\n",
    "        self.multi_web_search_investigator = EnhancedMultiWebSearchInvestigator()\n",
    "        self.multi_image_search_investigator = EnhancedMultiImageSearchInvestigator()\n",
    "        self.report_synthesizer = ReportSynthesizer()\n",
    "\n",
    "    def build_graph(self) -> Pregel:\n",
    "        workflow = StateGraph(AgentState)\n",
    "\n",
    "        # Add nodes with enhanced capabilities\n",
    "        workflow.add_node(\"supervisor\", self.supervisor.run)\n",
    "        workflow.add_node(\"multi_web_search_investigator\", self.multi_web_search_investigator.run)\n",
    "        workflow.add_node(\"multi_image_search_investigator\", self.multi_image_search_investigator.run)\n",
    "        workflow.add_node(\"report_synthesizer\", self.report_synthesizer.run)\n",
    "\n",
    "        # Define edges\n",
    "        workflow.add_edge(\"multi_web_search_investigator\", \"supervisor\")\n",
    "        workflow.add_edge(\"multi_image_search_investigator\", \"supervisor\")\n",
    "        workflow.add_edge(\"report_synthesizer\", END)\n",
    "\n",
    "        # Conditional edges from supervisor\n",
    "        workflow.add_conditional_edges(\n",
    "            \"supervisor\",\n",
    "            self.supervisor.route_to_worker,\n",
    "            {\n",
    "                \"multi_web_search_investigator\": \"multi_web_search_investigator\",\n",
    "                \"multi_image_search_investigator\": \"multi_image_search_investigator\",\n",
    "                \"report_synthesizer\": \"report_synthesizer\",\n",
    "                \"end\": END\n",
    "            }\n",
    "        )\n",
    "\n",
    "        workflow.set_entry_point(\"supervisor\")\n",
    "        return workflow.compile()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449eb7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage Example with Enhanced System\n",
    "enhanced_graph_builder = EnhancedMultiGraphBuilder(max_steps=6)  # Configurable step limit\n",
    "enhanced_app = enhanced_graph_builder.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Find the online identity of the hoster at https://www.airbnb.com/users/show/698886341\"\n",
    "# Enhanced initial state\n",
    "enhanced_state = {\n",
    "    \"original_query\": \"Find the online identity of the hoster at https://www.airbnb.com/users/show/698886341\",\n",
    "    \"plan\": None,\n",
    "    \"past_steps\": [],\n",
    "    \"aggregated_results\": {},\n",
    "    \"final_report\": \"\",\n",
    "    \"messages\": [],\n",
    "    \"last_step_result\": None,\n",
    "    \"last_step_message\": None,\n",
    "    \"awaiting_user_confirmation\": False,\n",
    "    \"candidate_options\": [],\n",
    "    \"selected_candidate\": None,\n",
    "    # Enhanced fields\n",
    "    \"current_step\": 0,\n",
    "    \"max_steps\": 6,\n",
    "    \"executed_tasks\": [],\n",
    "    \"failed_approaches\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = await enhanced_app.ainvoke(enhanced_state, config={\"recursion_limit\": 30})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
